import os
from typing import List, Optional

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
import fitz

# =========================
# í™˜ê²½/ê¸°ë³¸ ì„¤ì •
# =========================
load_dotenv()
PDF_FOLDER = os.getenv("PDF_FOLDER", "./pdfs")
PERSIST_DIR = os.getenv("PERSIST_DIR", "./vector_store")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ì „ì—­ ìƒíƒœ(ì•± ìˆ˜ëª…ì£¼ê¸° ë™ì•ˆ 1íšŒ ë¡œë”©)
_db = None
_retriever = None
_chain = None


# =========================
# ê¸°ì¡´ ë¡œì§ (ì¡°ê¸ˆë§Œ ì •ë¦¬)
# =========================
def extract_text_from_pdfs(pdf_folder: str) -> List[Document]:
    docs: List[Document] = []
    if not os.path.isdir(pdf_folder):
        print(f"âš ï¸ PDF í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {pdf_folder}")
        return docs

    for file in os.listdir(pdf_folder):
        if file.lower().endswith(".pdf"):
            path = os.path.join(pdf_folder, file)
            print(f"Loading: {file}")
            try:
                with fitz.open(path) as pdf:
                    text = ""
                    for page in pdf:
                        text += page.get_text("text")
                    if text.strip():
                        docs.append(Document(
                            page_content=text.strip(),
                            metadata={"source": file}
                        ))
            except Exception as e:
                print(f"Error loading {file}: {e}")

    print(f"\nâœ… ì´ {len(docs)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return docs


def chunk_documents(docs, chunk_size=800, chunk_overlap=150):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", ".", " "]
    )
    splits = splitter.split_documents(docs)
    print(f"ì´ {len(splits)}ê°œì˜ ì²­í¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return splits


def build_vector_db(splits, persist_dir: str):
    if not OPENAI_API_KEY:
        raise ValueError("âŒ OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=OPENAI_API_KEY
    )

    db = Chroma.from_documents(
        splits,
        embedding=embeddings,
        persist_directory=persist_dir
    )
    db.persist()
    print(f"âœ… Chroma ë²¡í„°DB ìƒì„± ì™„ë£Œ â†’ {persist_dir}")
    return db


def load_or_create_db(pdf_folder: str, persist_dir: str):
    """
    persist_dirì— ê¸°ì¡´ DBê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±.
    """
    global _db
    if os.path.isdir(persist_dir) and os.listdir(persist_dir):
        # ê¸°ì¡´ DB ë¡œë“œ
        print("ğŸ“¦ ê¸°ì¡´ Chroma DB ë¡œë“œ ì¤‘...")
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            api_key=OPENAI_API_KEY
        )
        _db = Chroma(
            embedding_function=embeddings,
            persist_directory=persist_dir
        )
        print("âœ… ê¸°ì¡´ DB ë¡œë“œ ì™„ë£Œ")
    else:
        # ìƒˆë¡œ ìƒì„±
        print("ğŸ†• DBê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
        docs = extract_text_from_pdfs(pdf_folder)
        if not docs:
            raise RuntimeError("PDFì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì§€ ëª»í•´ DBë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        splits = chunk_documents(docs)
        _db = build_vector_db(splits, persist_dir)
    return _db


def format_docs(docs: List[Document]) -> str:
    merged = []
    for d in docs:
        src = d.metadata.get("source", "unknown")
        merged.append(f"[{src}]\n{d.page_content}")
    return "\n\n---\n\n".join(merged)


def build_rag_chain(retriever):
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "ë„ˆëŠ” ê³ ê°ì§€ì› RAG ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì•„ë˜ 'ì»¨í…ìŠ¤íŠ¸'ë§Œ ê·¼ê±°ë¡œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µí•´. "
         "ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ê³  ì¶”ì¸¡í•˜ì§€ ë§ˆ. ì¤‘ìš”í•œ ìˆ˜ì¹˜/ì¡°ê±´ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , "
         "ëì— ê°„ë‹¨íˆ ê·¼ê±° ë¬¸ì„œëª…ì„ ë‚˜ì—´í•´."),
        ("human",
         "ì§ˆë¬¸: {question}\n\nì»¨í…ìŠ¤íŠ¸:\n{context}")
    ])

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
        api_key=OPENAI_API_KEY
    )

    chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return chain


def ask_once(chain, retriever, question: str):
    answer = chain.invoke(question)
    top_docs = retriever.get_relevant_documents(question)
    sources = [d.metadata.get("source", "unknown") for d in top_docs]
    return answer, sources


# =========================
# FastAPI ìŠ¤í‚¤ë§ˆ
# =========================
class AskRequest(BaseModel):
    question: str
    k: Optional[int] = 3


class AskResponse(BaseModel):
    answer: str
    sources: List[str]


class IngestRequest(BaseModel):
    pdf_folder: Optional[str] = None
    chunk_size: Optional[int] = 800
    chunk_overlap: Optional[int] = 150


class IngestResponse(BaseModel):
    message: str
    num_docs: int
    num_chunks: int


# =========================
# FastAPI ì•±
# =========================
app = FastAPI(title="RAG with FastAPI", version="1.0.0")


@app.on_event("startup")
def on_startup():
    """
    ì„œë²„ ì‹œì‘ ì‹œ 1) DB ë¡œë“œ/ìƒì„± 2) retriever/chain ì¤€ë¹„
    """
    global _db, _retriever, _chain

    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .envì— ì„¤ì •í•˜ì„¸ìš”.")

    _db = load_or_create_db(PDF_FOLDER, PERSIST_DIR)
    _retriever = _db.as_retriever(search_kwargs={"k": 3})
    _chain = build_rag_chain(_retriever)
    print("ğŸš€ RAG ì•± ì¤€ë¹„ ì™„ë£Œ")


@app.get("/health")
def health():
    return {"status": "ok"}


@app.post("/ask", response_model=AskResponse)
def ask(req: AskRequest):
    global _chain, _retriever
    if _chain is None or _retriever is None:
        raise HTTPException(status_code=503, detail="RAGê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    try:
        # kê°€ ë°”ë€Œë©´ ìš”ì²­ë§ˆë‹¤ ì¼ì‹œì ìœ¼ë¡œ retriever kë§Œ ì¡°ì •
        if req.k and req.k > 0:
            retriever = _db.as_retriever(search_kwargs={"k": req.k})
        else:
            retriever = _retriever

        # ì„ì‹œ ì²´ì¸(ì»¨í…ìŠ¤íŠ¸ ê²½ë¡œë§Œ retriever êµì²´)
        temp_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | _chain.steps[1]  # prompt
            | _chain.steps[2]  # llm
            | _chain.steps[3]  # parser
        )

        answer, sources = ask_once(temp_chain, retriever, req.question)
        return AskResponse(answer=answer, sources=sources)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ingest", response_model=IngestResponse)
def ingest(req: IngestRequest):
    """
    PDFë¥¼ ë‹¤ì‹œ ì½ì–´ ë²¡í„°DBë¥¼ ì¬êµ¬ì¶•(ê°±ì‹ )í•©ë‹ˆë‹¤.
    - ë¬´ê±°ìš´ ì‘ì—…ì´ë‹ˆ í•„ìš”í•  ë•Œë§Œ í˜¸ì¶œí•˜ì„¸ìš”.
    """
    global _db, _retriever, _chain

    try:
        folder = req.pdf_folder or PDF_FOLDER
        docs = extract_text_from_pdfs(folder)
        if not docs:
            raise HTTPException(status_code=400, detail="PDF í´ë”ì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        splits = chunk_documents(docs, chunk_size=req.chunk_size, chunk_overlap=req.chunk_overlap)

        # ê¸°ì¡´ persist ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”(ì„ íƒ: ì—¬ê¸°ì„œëŠ” ë®ì–´ì“°ê¸°)
        if os.path.isdir(PERSIST_DIR):
            # ì•ˆì „í•˜ê²Œ ê¸°ì¡´ ì„ë² ë”© ì‚­ì œë¥¼ ì›í•˜ë©´ ì•„ë˜ì²˜ëŸ¼ í´ë”ë¥¼ ë¹„ìš°ëŠ” ë¡œì§ì„ ë„£ì„ ìˆ˜ ìˆìŒ
            # ë‹¨, ìš´ì˜í™˜ê²½ì—ì„  ì£¼ì˜!
            for name in os.listdir(PERSIST_DIR):
                path = os.path.join(PERSIST_DIR, name)
                if os.path.isfile(path):
                    os.remove(path)
                else:
                    # í•˜ìœ„ ë””ë ‰í† ë¦¬ ì‚­ì œ
                    import shutil
                    shutil.rmtree(path)

        _db = build_vector_db(splits, PERSIST_DIR)
        _retriever = _db.as_retriever(search_kwargs={"k": 3})
        _chain = build_rag_chain(_retriever)

        return IngestResponse(
            message="ë²¡í„°DB ì¬êµ¬ì¶• ì™„ë£Œ",
            num_docs=len(docs),
            num_chunks=len(splits),
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
